<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Franziska Hirt" />

<meta name="date" content="2019-08-19" />

<title>Analyses for the paper: Measuring emotions during learning</title>

<script src="FaceReader_analyses_brms_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="FaceReader_analyses_brms_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="FaceReader_analyses_brms_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="FaceReader_analyses_brms_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="FaceReader_analyses_brms_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="FaceReader_analyses_brms_files/navigation-1.1/tabsets.js"></script>
<link href="FaceReader_analyses_brms_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="FaceReader_analyses_brms_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Analyses for the paper: Measuring emotions during learning</h1>
<h4 class="author">Franziska Hirt</h4>
<h4 class="date">19 August 2019</h4>

</div>


<div id="preparations" class="section level1">
<h1>1. PREPARATIONS</h1>
<pre class="r"><code># load packages
library(tidyverse)
library(rstan)
library(brms)
library(bayesplot)
library(ggmcmc) # for ggs posterior plot

# set rstan options
rstan::rstan_options(auto_write = T)
options(mc.cores = parallel::detectCores())</code></pre>
<div id="selection-of-statistical-methods" class="section level2">
<h2>Selection of statistical methods</h2>
<ul>
<li><p>Bayesian statistics, as they are more intuitive to interpret.</p></li>
<li><p>Mixed models, because events (level 1) are nested within participants (level 2) and texts (level 2). However, only random intercepts are included, as additional random effects would be hardly identifyable.</p></li>
<li><p>Treat emotional self-reports as ordinal outcome variables. Cummulative family in brms, as we understand the Likert-scales as the categorization of a latent continuous construct (Buerkner &amp; Vuorre, 2019: <a href="https://journals.sagepub.com/doi/full/10.1177/2515245918823199" class="uri">https://journals.sagepub.com/doi/full/10.1177/2515245918823199</a>).</p></li>
<li><p>Assummption of equal variances: “If unequal variances are theoretically possible – and they usually are – we also recommend incorporating them into the model” (Buerkner &amp; Vuorre, 2019). However, models allowing for unequal variances did not converge and were therefore omitted.</p></li>
</ul>
<div id="choosing-link-function" class="section level3">
<h3>Choosing link function:</h3>
<p>link-distributions available for cummulative models in brms (usually only minor impact on results): logit = logistic, probit = gaussian, cloglog = extreme value distribution <a href="http://bayesium.com/which-link-function-logit-probit-or-cloglog/" class="uri">http://bayesium.com/which-link-function-logit-probit-or-cloglog/</a></p>
<p>The choice should be made based on some combination of: - Knowledge of the response distribution, - Theoretical considerations, and - Empirical fit to the data. <a href="https://stats.stackexchange.com/questions/20523/difference-between-logit-and-probit-models" class="uri">https://stats.stackexchange.com/questions/20523/difference-between-logit-and-probit-models</a></p>
</div>
<div id="interpretation-of-summary-of-fitted-model" class="section level3">
<h3>interpretation of summary of fitted model</h3>
<ul>
<li>Estimate is the mean of the posterior distribution, and corresponds to the frequentist point estimate</li>
<li>Est.Error is the standard deviation of the posterior distribution</li>
<li>thresholds in ordinal models are called “intercepts” in the output</li>
<li>Visualisation of marginal effects for ordinal models: <a href="https://github.com/paul-buerkner/brms/issues/190" class="uri">https://github.com/paul-buerkner/brms/issues/190</a></li>
</ul>
</div>
<div id="posterior-predictive-checks-not-included-in-this-document" class="section level3">
<h3>posterior predictive checks (not included in this document)</h3>
<p>for ordinal models pp_check not adequate: <a href="https://github.com/stan-dev/bayesplot/issues/73" class="uri">https://github.com/stan-dev/bayesplot/issues/73</a> –&gt; use ppc: <a href="https://mc-stan.org/bayesplot/articles/graphical-ppcs.html" class="uri">https://mc-stan.org/bayesplot/articles/graphical-ppcs.html</a></p>
</div>
</div>
<div id="load-data" class="section level2">
<h2>load data</h2>
<pre class="r"><code># load data
df &lt;- read_csv(&quot;df_TEEM_final.csv&quot;)

# rename some variables
df &lt;- df %&gt;% rename(&quot;participant&quot; = &quot;subject_nr&quot;, &quot;text&quot; = &quot;text_pic&quot;, &quot;valence_post&quot; = &quot;SAM_LIKERT_POST&quot;)</code></pre>
</div>
<div id="standardize-predictors-aggregated-from-facereader" class="section level2">
<h2>standardize predictors (aggregated from FaceReader)</h2>
<p>(helps for model convergence and for the interpretation of the interaction effects)</p>
<pre class="r"><code>df &lt;- df %&gt;% 
  mutate(
    mean_interest = scale(mean_interest, center = T, scale = T),
    mean_boredom = scale(mean_boredom, center = T, scale = T),
    mean_valence = scale(mean_valence, center = T), scale = T)

df &lt;- df %&gt;% 
  mutate(
    sd_interest = scale(sd_interest, center = T, scale = T),
    sd_boredom = scale(sd_boredom, center = T, scale = T),
    sd_valence = scale(sd_valence, center = T), scale = T)

df &lt;- df %&gt;% 
  mutate(
    peak10_interest = scale(peak10_interest, center = T, scale = T),
    peak10_boredom = scale(peak10_boredom, center = T, scale = T),
    peak10_valence_pos = scale(peak10_valence_pos, center = T, scale = T),
    peak10_valence_neg = scale(peak10_valence_neg), center = T, scale = T)</code></pre>
</div>
</div>
<div id="interest" class="section level1">
<h1>2. INTEREST</h1>
<div id="interest-restricted-model" class="section level2">
<h2>INTEREST restricted model</h2>
<pre class="r"><code># complete cases only (drop NAs)
dfsub &lt;- df %&gt;% select(participant, interested_post, mean_interest, sd_interest, peak10_interest, text) %&gt;% drop_na()

# restricted model
m0i_cloglog &lt;- brm(
          interested_post ~ 1 + (1|participant) + (1|text),
          family = cumulative(&quot;cloglog&quot;),                    
          prior = prior(cauchy(0, 10), class = sd), 
          iter = 4000, warmup = 2000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.99),
          inits = 0,
          data = dfsub,
          save_all_pars = T) # needed for bayes factor

summary(m0i_cloglog)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: interested_post ~ 1 + (1 | participant) + (1 | text) 
##    Data: dfsub (Number of observations: 205) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 103) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.52      0.28     1.01     2.10       1663 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.73      0.43     0.24     1.83       2457 1.00
## 
## Population-Level Effects: 
##              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]    -5.53      0.81    -7.26    -4.09       3740 1.00
## Intercept[2]    -3.07      0.50    -4.11    -2.16       3798 1.00
## Intercept[3]    -1.56      0.43    -2.41    -0.75       4062 1.00
## Intercept[4]     0.98      0.42     0.21     1.89       3773 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># other link functions
m0i_logit &lt;-  update(m0i_cloglog,
                    family = cumulative(&quot;logit&quot;))

m0i_probit &lt;-  update(m0i_cloglog,
                      family = cumulative(&quot;probit&quot;))
# compare different link functions using assimilation of leave-one-out-cross validation (looic)
m0i_logit &lt;- add_criterion(m0i_logit,&quot;loo&quot;, reloo = T) #&quot;reloo = T&quot; actually calculates MCMC for problematic observations 
m0i_probit &lt;- add_criterion(m0i_probit,&quot;loo&quot;, reloo = T) 
m0i_cloglog &lt;- add_criterion(m0i_cloglog ,&quot;loo&quot;, reloo = T)
print(loo_compare(m0i_logit, m0i_probit, m0i_cloglog, criterion=&quot;loo&quot;), simplify = F)  # cloglog 1.5-3.5 SD better</code></pre>
<pre><code>##             elpd_diff se_diff elpd_loo se_elpd_loo p_loo  se_p_loo looic 
## m0i_cloglog    0.0       0.0  -239.6     11.8        74.9    5.8    479.1
## m0i_probit    -1.9       1.4  -241.5     11.5        71.5    6.0    483.0
## m0i_logit     -2.0       1.3  -241.5     11.6        76.5    5.7    483.0
##             se_looic
## m0i_cloglog   23.5  
## m0i_probit    23.0  
## m0i_logit     23.1</code></pre>
<pre class="r"><code># chosen response distribution (link function) for final restricted model
m0i &lt;- m0i_cloglog</code></pre>
</div>
<div id="interest-mean" class="section level2">
<h2>INTEREST mean</h2>
<pre class="r"><code># full model including FaceReader&#39;s estimate as predictor
m1_imean &lt;-  update(m0i, formula. = ~ . + mean_interest,
                    prior = c(prior(normal(0, 10), class = b), 
                              prior(cauchy(0, 10), class = sd)), 
                    newdata = dfsub,
                    save_all_pars = T)

## model parameter
summary(m1_imean)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: interested_post ~ (1 | participant) + (1 | text) + mean_interest 
##    Data: dfsub (Number of observations: 205) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 103) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.49      0.27     0.99     2.06       1475 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.70      0.40     0.23     1.69       2715 1.00
## 
## Population-Level Effects: 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]     -5.66      0.85    -7.53    -4.17       3859 1.00
## Intercept[2]     -3.08      0.49    -4.13    -2.18       3704 1.00
## Intercept[3]     -1.56      0.41    -2.43    -0.78       4271 1.00
## Intercept[4]      0.97      0.40     0.21     1.83       4362 1.00
## mean_interest    -0.23      0.16    -0.53     0.09       5384 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># plots
plot(marginal_effects(m1_imean, &quot;mean_interest&quot;, categorical = F), points = T, point_args = c(alpha = 0.8)) # shows the strong influence of two obervations</code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-5-1.png" /><!-- --></p>
<pre class="r"><code># Model without &quot;outliers&quot;
dfsub_out &lt;- dfsub %&gt;% 
  filter(mean_interest &lt; (mean(mean_interest) + 4*sd(mean_interest)) &amp; mean_interest &gt; (mean(mean_interest) - 4*sd(mean_interest))) 
# resulting in two observations less
# dfsub %&gt;% filter(mean_interest &gt; (mean(mean_interest) + 4*sd(mean_interest)) | mean_interest &lt; (mean(mean_interest) - 4*sd(mean_interest))) # ouliers are from one participant (highly expressive in video)

m1_imean_out &lt;-  update(m0i, formula. = ~ . + mean_interest,
                    prior = c(prior(normal(0, 10), class = b), 
                              prior(cauchy(0, 10), class = sd)), 
                    newdata = dfsub_out,
                    save_all_pars = T)
summary(m1_imean_out)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: interested_post ~ (1 | participant) + (1 | text) + mean_interest 
##    Data: dfsub_out (Number of observations: 203) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 102) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.52      0.27     1.00     2.08       1748 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.76      0.48     0.25     1.92       2629 1.00
## 
## Population-Level Effects: 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]     -5.48      0.80    -7.22    -4.04       3600 1.00
## Intercept[2]     -3.09      0.50    -4.13    -2.18       3813 1.00
## Intercept[3]     -1.58      0.43    -2.45    -0.77       3964 1.00
## Intercept[4]      0.98      0.43     0.22     1.88       3946 1.00
## mean_interest    -0.15      0.32    -0.77     0.50       5419 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>## plots    
plot(marginal_effects(m1_imean_out, &quot;mean_interest&quot;, categorical = F), points = T, point_args = c(alpha = 0.8))</code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-5-2.png" /><!-- --></p>
<pre class="r"><code># choose final model
m1_imean &lt;- m1_imean_out</code></pre>
</div>
<div id="interest-meansd" class="section level2">
<h2>INTEREST mean*SD</h2>
<pre class="r"><code># the participant from before also outlier in SD? --&gt; No.
#dfsub_out %&gt;% filter(sd_interest &gt; (mean(sd_interest) + 4*sd(sd_interest)) | sd_interest &lt; (mean(sd_interest) - 4*sd(sd_interest)))


# full model including FaceReader&#39;s estimates as predictor
m1_imeanxsd &lt;-  update(m0i, formula. = ~ . + mean_interest*sd_interest,
                    prior = c(prior(normal(0, 10), class = b), 
                              prior(cauchy(0, 10), class = sd)),
                    newdata = dfsub_out, # without outliers of mean interest
                    save_all_pars = T)

## model indicator
summary(m1_imeanxsd)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: interested_post ~ (1 | participant) + (1 | text) + mean_interest + sd_interest + mean_interest:sd_interest 
##    Data: dfsub_out (Number of observations: 203) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 102) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.54      0.28     1.02     2.14       1702 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.74      0.42     0.25     1.83       2771 1.00
## 
## Population-Level Effects: 
##                           Estimate Est.Error l-95% CI u-95% CI Eff.Sample
## Intercept[1]                 -5.56      0.84    -7.35    -4.09       3422
## Intercept[2]                 -3.15      0.54    -4.29    -2.16       3661
## Intercept[3]                 -1.62      0.47    -2.58    -0.75       3718
## Intercept[4]                  0.98      0.46     0.11     1.95       2842
## mean_interest                -0.41      1.12    -2.70     1.72       3288
## sd_interest                   0.24      0.38    -0.50     1.01       3714
## mean_interest:sd_interest    -0.04      0.33    -0.65     0.66       3842
##                           Rhat
## Intercept[1]              1.00
## Intercept[2]              1.00
## Intercept[3]              1.00
## Intercept[4]              1.00
## mean_interest             1.00
## sd_interest               1.00
## mean_interest:sd_interest 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># plots
plot(marginal_effects(m1_imeanxsd,&quot;mean_interest:sd_interest&quot;, categorical = F), points = T) </code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-6-1.png" /><!-- --></p>
<pre class="r"><code>plot(marginal_effects(m1_imeanxsd,&quot;mean_interest&quot;, categorical = F), points = T) </code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-6-2.png" /><!-- --></p>
<pre class="r"><code>plot(marginal_effects(m1_imeanxsd,&quot;sd_interest&quot;, categorical = F), points = T) </code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-6-3.png" /><!-- --></p>
</div>
<div id="interest-mean-of-peaks" class="section level2">
<h2>INTEREST mean of peaks</h2>
<pre class="r"><code># remove outliers also in peak when from the same participant as in mean:
dfsub_outpeak &lt;- dfsub %&gt;% filter(peak10_interest &lt; (mean(peak10_interest) + 4*sd(peak10_interest)) &amp; peak10_interest &gt; (mean(peak10_interest) - 4*sd(peak10_interest))) 
# dfsub %&gt;% filter(peak10_interest &gt; (mean(peak10_interest) + 4*sd(peak10_interest)) | peak10_interest &lt; (mean(peak10_interest) - 4*sd(peak10_interest)))  # 2 ouliers are from the same participant as before

# model including outliers
m1_ipeak &lt;- update(m0i, formula. = ~ . + peak10_interest,
                    prior = c(prior(normal(0, 10), class = b), 
                              prior(cauchy(0, 10), class = sd)),
                              newdata = dfsub,
                              save_all_pars = T)
summary(m1_ipeak)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: interested_post ~ (1 | participant) + (1 | text) + peak10_interest 
##    Data: dfsub (Number of observations: 205) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 103) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.54      0.27     1.03     2.12       1773 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.74      0.45     0.25     1.83       2392 1.00
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]       -5.60      0.83    -7.39    -4.13       4087 1.00
## Intercept[2]       -3.11      0.51    -4.19    -2.18       3378 1.00
## Intercept[3]       -1.58      0.43    -2.48    -0.77       3579 1.00
## Intercept[4]        0.98      0.42     0.21     1.85       3178 1.00
## peak10_interest    -0.21      0.17    -0.55     0.13       3982 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># model without outliers
m1_ipeak_out &lt;- update(m0i, formula. = ~ . + peak10_interest,
                    prior = c(prior(normal(0, 10), class = b), 
                              prior(cauchy(0, 10), class = sd)),
                              newdata = dfsub_outpeak,
                              save_all_pars = T)

## model parameter 
summary(m1_ipeak_out)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: interested_post ~ (1 | participant) + (1 | text) + peak10_interest 
##    Data: dfsub_outpeak (Number of observations: 203) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 102) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.51      0.28     1.01     2.08       1615 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.72      0.40     0.23     1.81       2618 1.00
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]       -5.50      0.80    -7.20    -4.06       4020 1.00
## Intercept[2]       -3.10      0.50    -4.15    -2.19       3856 1.00
## Intercept[3]       -1.60      0.43    -2.45    -0.79       4200 1.00
## Intercept[4]        0.96      0.42     0.20     1.85       4070 1.00
## peak10_interest    -0.04      0.22    -0.48     0.41       4189 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># plots
plot(marginal_effects(m1_ipeak,&quot;peak10_interest&quot;, categorical = F), points = T, point_args = c(alpha = 0.8)) </code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-7-1.png" /><!-- --></p>
<pre class="r"><code>plot(marginal_effects(m1_ipeak_out,&quot;peak10_interest&quot;, categorical = F), points = T, point_args = c(alpha = 0.8))</code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-7-2.png" /><!-- --></p>
<pre class="r"><code># define final model
m1_peak &lt;- m1_ipeak_out</code></pre>
</div>
</div>
<div id="boredom" class="section level1">
<h1>3. BOREDOM</h1>
<div id="boredom-restricted-model" class="section level2">
<h2>BOREDOM restricted model</h2>
<pre class="r"><code># complete cases only (drop NAs)
dfsubb &lt;- df %&gt;% select(participant, bored_post, mean_boredom, sd_boredom, peak10_boredom, text) %&gt;% drop_na()

# restricted model
m0b_cloglog &lt;- brm(
          bored_post ~ 1 + (1|participant) + (1|text),
          family = cumulative(&quot;cloglog&quot;),
          prior = prior(cauchy(0, 10), class = sd),
          iter = 4000, warmup = 2000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.99),
          inits = 0,
          data = dfsubb,
          save_all_pars = T)

summary(m0b_cloglog)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: bored_post ~ 1 + (1 | participant) + (1 | text) 
##    Data: dfsubb (Number of observations: 204) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 102) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.49      0.36     0.86     2.29       1554 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.41      0.31     0.03     1.17       2204 1.00
## 
## Population-Level Effects: 
##              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]     0.45      0.31    -0.12     1.13       2614 1.00
## Intercept[2]     1.76      0.41     1.05     2.67       2019 1.00
## Intercept[3]     2.95      0.59     1.93     4.24       2034 1.00
## Intercept[4]     3.53      0.73     2.30     5.16       2163 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># other link functions
m0b_logit &lt;-  update(m0b_cloglog,
                    family = cumulative(&quot;logit&quot;))

m0b_probit &lt;-  update(m0b_cloglog,
                      family = cumulative(&quot;probit&quot;))

# compare different link functions
m0b_logit &lt;- add_criterion(m0b_logit,&quot;loo&quot;)
m0b_probit &lt;- add_criterion(m0b_probit,&quot;loo&quot;)
m0b_cloglog &lt;- add_criterion(m0b_cloglog ,&quot;loo&quot;)
print(loo_compare(m0b_logit, m0b_probit, m0b_cloglog, criterion=&quot;loo&quot;), simplify = F)</code></pre>
<pre><code>##             elpd_diff se_diff elpd_loo se_elpd_loo p_loo  se_p_loo looic 
## m0b_cloglog    0.0       0.0  -157.5     11.7        52.1    5.2    315.0
## m0b_probit    -8.6       1.8  -166.1     13.1        56.6    5.6    332.2
## m0b_logit    -12.4       2.6  -170.0     13.6        61.3    5.9    339.9
##             se_looic
## m0b_cloglog   23.4  
## m0b_probit    26.2  
## m0b_logit     27.2</code></pre>
<pre class="r"><code># chosen response distribution (link function)
m0b &lt;- m0b_cloglog</code></pre>
</div>
<div id="boredom-mean" class="section level2">
<h2>BOREDOM mean</h2>
<pre class="r"><code># full model including FaceReader&#39;s estimate as predictor
m1_bmean &lt;-  update(m0b, formula. = ~ . + mean_boredom,
                    prior = c(prior(normal(0, 10), class = b), 
                              prior(cauchy(0, 10), class = sd)), 
                    newdata = dfsubb,
                    save_all_pars = T)

## model parameter
summary(m1_bmean)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: bored_post ~ (1 | participant) + (1 | text) + mean_boredom 
##    Data: dfsubb (Number of observations: 204) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 102) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.56      0.38     0.90     2.41       1451 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.44      0.33     0.03     1.27       2363 1.00
## 
## Population-Level Effects: 
##              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]     0.48      0.33    -0.11     1.20       2655 1.00
## Intercept[2]     1.83      0.43     1.11     2.81       2025 1.00
## Intercept[3]     3.03      0.61     2.00     4.42       1852 1.00
## Intercept[4]     3.64      0.76     2.36     5.41       1995 1.00
## mean_boredom    -0.10      0.19    -0.50     0.26       3101 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># plots
plot(marginal_effects(m1_bmean, &quot;mean_boredom&quot;, categorical = F), points = T, point_args = c(alpha = 0.8)) </code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-9-1.png" /><!-- --></p>
</div>
<div id="boredom-meansd" class="section level2">
<h2>BOREDOM mean*SD</h2>
<pre class="r"><code># full model including FaceReader&#39;s estimates as predictor
m1_bmeanxsd &lt;-  update(m0b, formula. = ~ . + mean_boredom*sd_boredom,
                    prior = c(prior(normal(0, 10), class = b), 
                              prior(cauchy(0, 10), class = sd)),
                    newdata = dfsubb,
                    save_all_pars = T)
                    

## model indicators 
summary(m1_bmeanxsd)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: bored_post ~ (1 | participant) + (1 | text) + mean_boredom + sd_boredom + mean_boredom:sd_boredom 
##    Data: dfsubb (Number of observations: 204) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 102) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.77      0.45     1.03     2.80       1360 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.49      0.42     0.04     1.42       1087 1.00
## 
## Population-Level Effects: 
##                         Estimate Est.Error l-95% CI u-95% CI Eff.Sample
## Intercept[1]                0.87      0.47     0.07     1.90       1692
## Intercept[2]                2.31      0.60     1.33     3.62       1469
## Intercept[3]                3.61      0.80     2.30     5.37       1496
## Intercept[4]                4.30      0.96     2.70     6.42       1578
## mean_boredom               -0.28      0.38    -1.12     0.38       2566
## sd_boredom                 -0.04      0.32    -0.66     0.62       3397
## mean_boredom:sd_boredom     0.42      0.27    -0.04     1.00       2599
##                         Rhat
## Intercept[1]            1.00
## Intercept[2]            1.01
## Intercept[3]            1.01
## Intercept[4]            1.00
## mean_boredom            1.00
## sd_boredom              1.00
## mean_boredom:sd_boredom 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># plots
plot(marginal_effects(m1_bmeanxsd,&quot;mean_boredom:sd_boredom&quot;, categorical = F), points = T, point_args = c(alpha = 0.8))</code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-10-1.png" /><!-- --></p>
<pre class="r"><code>## plot densities and CIs of interaction-effect
m1_bmeanxsd_ggs &lt;- ggs(m1_bmeanxsd) # transforms the brms output into a longformat tibble (used to make different types of plots)
ggplot(filter(m1_bmeanxsd_ggs, Parameter == &quot;b_mean_boredom:sd_boredom&quot;, Iteration&gt;1000), aes(x=value)) +
  geom_density(fill = &quot;orange&quot;, alpha = .5) + geom_vline(xintercept = 0, col=&quot;red&quot;, size=1) +
  scale_x_continuous(name=&quot;Value&quot;, limits=c(-1, 2)) + 
  labs(title=&quot;Posterior density of interaction-effect&quot;) +
  geom_vline(xintercept = summary(m1_bmeanxsd)$fixed[7,3:4], col=&quot;blue&quot;, linetype=2) # 95% CrI</code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-10-2.png" /><!-- --></p>
<pre class="r"><code># 10-fold cross validation: interaction model compared to restricted model
m0b &lt;- add_criterion(m0b, criterion =  &quot;kfold&quot;, folds = &quot;grouped&quot;, group = &quot;participant&quot;)
m1_bmeanxsd &lt;- add_criterion(m1_bmeanxsd, criterion = &quot;kfold&quot;, folds = &quot;grouped&quot;, group = &quot;participant&quot;)
print(loo_compare(m0b, m1_bmeanxsd, criterion = &quot;kfold&quot;), simplify = T) ## Estimating out-of sample predictions (via 10-fold cross validation) of the interaction model, compared to a model with no predictors yielded better results for the model without the interaction. Accordingly, we consider this potential interaction effect as irrelevant. </code></pre>
<pre><code>##             elpd_diff se_diff
## m0b          0.0       0.0   
## m1_bmeanxsd -0.8       2.2</code></pre>
</div>
<div id="boredom-mean-of-peaks" class="section level2">
<h2>BOREDOM mean of peaks</h2>
<pre class="r"><code>m1_bpeak &lt;-  update(m0b, formula. = ~ . + peak10_boredom,
                    prior = c(prior(normal(0, 10), class = b), 
                              prior(cauchy(0, 10), class = sd)),
                    newdata = dfsubb,
                    save_all_pars = T)

## model parameter 
summary(m1_bpeak)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = cloglog; disc = identity 
## Formula: bored_post ~ (1 | participant) + (1 | text) + peak10_boredom 
##    Data: dfsubb (Number of observations: 204) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 102) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.56      0.38     0.91     2.44       1494 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.43      0.32     0.03     1.23       2184 1.00
## 
## Population-Level Effects: 
##                Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]       0.49      0.33    -0.11     1.22       3405 1.00
## Intercept[2]       1.84      0.44     1.09     2.83       2350 1.00
## Intercept[3]       3.05      0.62     2.00     4.44       2128 1.00
## Intercept[4]       3.66      0.77     2.37     5.37       2257 1.00
## peak10_boredom    -0.16      0.19    -0.56     0.19       4057 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># plots
plot(marginal_effects(m1_bpeak,&quot;peak10_boredom&quot;, categorical = F), points = T, point_args = c(alpha = 0.8)) </code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-11-1.png" /><!-- --></p>
</div>
</div>
<div id="valence" class="section level1">
<h1>4. VALENCE</h1>
<p>stronger priors for valence, as issues with convergence. ## VALENCE restricted model</p>
<pre class="r"><code>## select complete cases of relevant variables
dfsubv &lt;- df %&gt;% select(participant, valence_post, mean_valence, sd_valence, peak10_valence_pos, peak10_valence_neg, text) %&gt;% drop_na()

# restricted model
## probit-model
m0v_probit &lt;- brm(
          valence_post ~ 1 + (1|participant) + (1|text), 
          family = cumulative(&quot;probit&quot;),
          prior = c(prior(normal(0, 1), class = Intercept), 
                    prior(cauchy(0, 1), class = sd)),
          iter = 4000, warmup = 2000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999, max_treedepth = 15), 
          inits = 0,
          data = dfsubv,
          save_all_pars = T)
summary(m0v_probit)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = probit; disc = identity 
## Formula: valence_post ~ 1 + (1 | participant) + (1 | text) 
##    Data: dfsubv (Number of observations: 193) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 97) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.31      0.20     0.94     1.73       1496 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.55      0.57     0.01     1.98        761 1.00
## 
## Population-Level Effects: 
##              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]    -3.12      0.48    -4.07    -2.15       2105 1.00
## Intercept[2]    -2.82      0.43    -3.59    -1.87       1674 1.00
## Intercept[3]    -2.65      0.42    -3.36    -1.72       1437 1.00
## Intercept[4]    -2.35      0.42    -3.02    -1.38       1196 1.00
## Intercept[5]    -1.30      0.43    -1.92    -0.26       1005 1.00
## Intercept[6]    -0.18      0.45    -0.79     0.92        912 1.00
## Intercept[7]     1.33      0.49     0.67     2.51        876 1.00
## Intercept[8]     2.85      0.55     2.01     4.12        921 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># chosen response distribution (link function)
m0v &lt;- m0v_probit</code></pre>
<div id="valence-mean" class="section level2">
<h2>VALENCE mean</h2>
<pre class="r"><code># full model including FaceReader&#39;s estimate as predictor
m1_vmean &lt;-  update(m0v, formula. = ~ . + mean_valence,
                    prior = c(prior(normal(0, 1), class = Intercept),
                              prior(normal(0, 1), class = b), 
                              prior(cauchy(0, 1), class = sd)), 
                    newdata = dfsubv,
                    save_all_pars = T,
                    seed = 19) # for reproducibility (on the same machine) - to avoid &quot;Stan model x does not contain samples.&quot; which sometimes occured

## model parameter
summary(m1_vmean)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = probit; disc = identity 
## Formula: valence_post ~ (1 | participant) + (1 | text) + mean_valence 
##    Data: dfsubv (Number of observations: 193) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 97) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.34      0.20     0.96     1.75       1812 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.55      0.58     0.01     2.07        686 1.00
## 
## Population-Level Effects: 
##              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]    -3.13      0.48    -4.08    -2.14       2212 1.00
## Intercept[2]    -2.83      0.43    -3.61    -1.89       1597 1.00
## Intercept[3]    -2.67      0.42    -3.40    -1.75       1400 1.00
## Intercept[4]    -2.36      0.42    -3.04    -1.42       1152 1.00
## Intercept[5]    -1.31      0.43    -1.92    -0.27        886 1.00
## Intercept[6]    -0.19      0.45    -0.78     0.92        797 1.00
## Intercept[7]     1.34      0.49     0.67     2.53        797 1.00
## Intercept[8]     2.86      0.56     2.01     4.16        918 1.00
## mean_valence    -0.02      0.15    -0.31     0.27       3917 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># plots
plot(marginal_effects(m1_vmean, &quot;mean_valence&quot;, categorical = F), points = T, point_args = c(alpha = 0.8))</code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-13-1.png" /><!-- --></p>
</div>
<div id="valence-meansd" class="section level2">
<h2>VALENCE mean*SD</h2>
<pre class="r"><code># full model including FaceReader&#39;s estimates as predictor
m1_vmeanxsd &lt;-  update(m0v, formula. = ~ . + mean_valence*sd_valence,
                    prior = c(prior(normal(0, 1), class = Intercept),
                              prior(normal(0, 1), class = b), 
                              prior(cauchy(0, 1), class = sd)),
                    control = list(adapt_delta = 0.999, max_treedepth = 15), 
                    inits = 0,
                    newdata = dfsubv,
                    save_all_pars = T,
                    seed = 21) # for reproducibility (on the same machine) - to avoid divergent transitions which sometimes occured
                    
        
## model parameter
summary(m1_vmeanxsd)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = probit; disc = identity 
## Formula: valence_post ~ (1 | participant) + (1 | text) + mean_valence + sd_valence + mean_valence:sd_valence 
##    Data: dfsubv (Number of observations: 193) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 97) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.36      0.21     0.98     1.78       1594 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.60      0.62     0.01     2.15        704 1.01
## 
## Population-Level Effects: 
##                         Estimate Est.Error l-95% CI u-95% CI Eff.Sample
## Intercept[1]               -3.06      0.49    -4.05    -2.08       2020
## Intercept[2]               -2.77      0.44    -3.55    -1.83       1473
## Intercept[3]               -2.60      0.43    -3.34    -1.65       1309
## Intercept[4]               -2.29      0.44    -3.01    -1.30       1119
## Intercept[5]               -1.23      0.46    -1.91    -0.18        866
## Intercept[6]               -0.10      0.48    -0.76     1.03        790
## Intercept[7]                1.44      0.53     0.71     2.66        760
## Intercept[8]                2.99      0.59     2.07     4.32        827
## mean_valence                0.16      0.25    -0.32     0.65       2869
## sd_valence                  0.03      0.14    -0.25     0.31       4093
## mean_valence:sd_valence    -0.14      0.15    -0.44     0.15       3355
##                         Rhat
## Intercept[1]            1.00
## Intercept[2]            1.00
## Intercept[3]            1.00
## Intercept[4]            1.00
## Intercept[5]            1.01
## Intercept[6]            1.01
## Intercept[7]            1.01
## Intercept[8]            1.01
## mean_valence            1.00
## sd_valence              1.00
## mean_valence:sd_valence 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># plots
plot(marginal_effects(m1_vmeanxsd,&quot;mean_valence:sd_valence&quot;), points = T, point_args = c(alpha = 0.8)) </code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-14-1.png" /><!-- --></p>
</div>
<div id="valence-mean-of-peaks" class="section level2">
<h2>VALENCE mean of peaks</h2>
<pre class="r"><code>m1_vpeak &lt;-  update(m0v, formula. = ~ . + peak10_valence_neg + peak10_valence_pos,
                    prior = c(prior(normal(0, 1), class = Intercept),
                              prior(normal(0, 1), class = b), 
                              prior(cauchy(0, 1), class = sd)),
                    newdata = dfsubv,
                    save_all_pars = T)

## model parameter 
summary(m1_vpeak)</code></pre>
<pre><code>##  Family: cumulative 
##   Links: mu = probit; disc = identity 
## Formula: valence_post ~ (1 | participant) + (1 | text) + peak10_valence_neg + peak10_valence_pos 
##    Data: dfsubv (Number of observations: 193) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~participant (Number of levels: 97) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.34      0.20     0.97     1.79       1666 1.00
## 
## ~text (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.56      0.58     0.02     2.05        789 1.00
## 
## Population-Level Effects: 
##                    Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept[1]          -3.13      0.49    -4.09    -2.16       2249 1.00
## Intercept[2]          -2.82      0.43    -3.60    -1.89       1684 1.00
## Intercept[3]          -2.65      0.43    -3.40    -1.71       1541 1.00
## Intercept[4]          -2.35      0.43    -3.05    -1.37       1277 1.00
## Intercept[5]          -1.30      0.45    -1.94    -0.21       1035 1.00
## Intercept[6]          -0.18      0.46    -0.79     0.95        961 1.00
## Intercept[7]           1.36      0.50     0.69     2.56        931 1.00
## Intercept[8]           2.89      0.56     2.04     4.21       1061 1.00
## peak10_valence_neg    -0.06      0.14    -0.34     0.23       3692 1.00
## peak10_valence_pos     0.03      0.12    -0.22     0.27       4991 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code># plots
plot(marginal_effects(m1_vpeak,&quot;peak10_valence_neg&quot;, categorical = F), points = T, point_args = c(alpha = 0.8)) </code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-15-1.png" /><!-- --></p>
<pre class="r"><code>plot(marginal_effects(m1_vpeak,&quot;peak10_valence_pos&quot;, categorical = F), points = T, point_args = c(alpha = 0.8)) </code></pre>
<p><img src="FaceReader_analyses_brms_files/figure-html/unnamed-chunk-15-2.png" /><!-- --></p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
